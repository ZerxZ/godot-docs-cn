<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE document PUBLIC "+//IDN docutils.sourceforge.net//DTD Docutils Generic//EN//XML" "http://docutils.sourceforge.net/docs/ref/docutils.dtd">
<!-- Generated by Docutils 0.21.2 -->
<document source="/home/runner/work/godot-docs-cn/godot-docs-cn/godot-docs/docs/tutorials/xr/xr_action_map.rst" translation_progress="{'total': 0, 'translated': 0}" xmlns:c="https://www.sphinx-doc.org/" xmlns:changeset="https://www.sphinx-doc.org/" xmlns:citation="https://www.sphinx-doc.org/" xmlns:cpp="https://www.sphinx-doc.org/" xmlns:index="https://www.sphinx-doc.org/" xmlns:js="https://www.sphinx-doc.org/" xmlns:math="https://www.sphinx-doc.org/" xmlns:py="https://www.sphinx-doc.org/" xmlns:rst="https://www.sphinx-doc.org/" xmlns:std="https://www.sphinx-doc.org/">
    <target refid="doc-xr-action-map"></target>
    <section ids="the-xr-action-map doc-xr-action-map" names="the\ xr\ action\ map doc_xr_action_map">
        <title>The XR action map</title>
        <paragraph>Godot has an action map feature as part of the XR system.
            At this point in time this system is part of the OpenXR module.
            There are plans to encompass WebXR into this in the near future hence we call it
            the XR action map system in this document.
            It implements the built-in action map system of OpenXR mostly exactly as it is offered.</paragraph>
        <paragraph>The XR action map system exposes input, positional data and output for XR controllers
            to your game/application.
            It does this by exposing named actions that can be tailored to your game/application
            and binding these to the actual inputs and outputs on your XR devices.</paragraph>
        <paragraph>As the XR action map is currently part of the OpenXR module, OpenXR needs to be enabled
            in your project settings to expose it:</paragraph>
        <image candidates="{'*': 'tutorials/xr/img/openxr_enabled.webp'}" original_uri="img/openxr_enabled.webp" uri="tutorials/xr/img/openxr_enabled.webp"></image>
        <paragraph>You will then find the XR Action Map interface in the bottom of the screen:</paragraph>
        <image candidates="{'*': 'tutorials/xr/img/xr_action_map.webp'}" original_uri="img/xr_action_map.webp" uri="tutorials/xr/img/xr_action_map.webp"></image>
        <note>
            <paragraph>Godot's built-in input system has many things in common with the XR action map system.
                In fact our original idea was to add functionality to the existing input system and
                expose the data to the OpenXR action map system.
                We may revisit that idea at some point but as it turns out there were just too many
                problems to overcome.
                To name a few:</paragraph>
            <block_quote>
                <bullet_list bullet="*">
                    <list_item>
                        <paragraph>Godot's input system mainly centers around button inputs, XR adds triggers, axis,
                            poses and haptics (output) into the mix.
                            This would greatly complicate the input system with features that won't work for
                            normal controllers or contrast with the current approach.
                            It was felt this would lead to confusion for the majority of Godot users.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>Godot's input system works with raw input data that is parsed and triggers emitting
                            actions.
                            This input data is made available to the end user.
                            OpenXR completely hides raw data and does all the parsing for us, we only get
                            access to already parsed action data.
                            This inconsistency is likely to lead to bugs when an unsuspecting user tries to use
                            an XR device as a normal input device.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>Godot's input system allows changes to what inputs are bound to actions in runtime,
                            OpenXR does not.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>Godot's input system is based on device ids which are meaningless in OpenXR.</paragraph>
                    </list_item>
                </bullet_list>
            </block_quote>
            <paragraph>This does mean that a game/application that mixes traditional inputs with XR
                controllers will have a separation.
                For most applications either one or the other is used and this is not seen as a problem.
                In the end, it's a limitation of the system.</paragraph>
        </note>
        <section ids="the-default-action-map" names="the\ default\ action\ map">
            <title>The default action map</title>
            <paragraph>Godot will automatically create a default action map if no action map file is found.</paragraph>
            <warning>
                <paragraph>This default map was designed to help developers port their XR games/applications from
                    Godot 3 to Godot 4.
                    As a result this map essentially binds all known inputs on all controllers supported by
                    default, to actions one on one.
                    This is not a good example of setting up an action map.
                    It does allow a new developer to have a starting point when they want to become
                    familiar with Godot XR.
                    It prevents having to design a proper action map for their game/application first.</paragraph>
            </warning>
            <paragraph>For this walkthrough we're going to start with a blank action map.
                You can delete the "Godot action set" entry at the top by pressing the trash can icon.
                This will clear out all actions.
                You might also want to remove the controllers that you do not wish to setup,
                more on this later.</paragraph>
        </section>
        <section ids="action-sets" names="action\ sets">
            <title>Action sets</title>
            <note>
                <paragraph>Before we dive in, you will see the term XR runtime used throughout this document.
                    With XR runtime we mean the software that is controlling and interacting with
                    the AR or VR headset.
                    The XR runtime then exposes this to us through an API such as OpenXR.
                    So:</paragraph>
                <block_quote>
                    <bullet_list bullet="*">
                        <list_item>
                            <paragraph>for Steam this is SteamVR,</paragraph>
                        </list_item>
                        <list_item>
                            <paragraph>for Meta on desktop this is the Oculus Client (including when using Quest link),</paragraph>
                        </list_item>
                        <list_item>
                            <paragraph>for Meta on Quest this is the Quest's native OpenXR client,</paragraph>
                        </list_item>
                        <list_item>
                            <paragraph>on Linux this could be Monado, etc.</paragraph>
                        </list_item>
                    </bullet_list>
                </block_quote>
            </note>
            <paragraph>The action map allows us to organize our actions in sets.
                Each set can be enabled or disabled on its own.</paragraph>
            <paragraph>The concept here is that you could have different sets that provide bindings
                in different scenarios.
                You could have:</paragraph>
            <block_quote>
                <bullet_list bullet="*">
                    <list_item>
                        <paragraph>a <literal>Character control</literal> set for when you're walking around,</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>a <literal>Vehicle control</literal> set for when you're operating a vehicle,</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>a <literal>Menu</literal> set for when a menu is open.</paragraph>
                    </list_item>
                </bullet_list>
            </block_quote>
            <paragraph>Only the action set applicable to the current state of your game/application
                can then be enabled.</paragraph>
            <paragraph>This is especially important if you wish to bind the same input on a controller
                to a different action.
                For instance:</paragraph>
            <block_quote>
                <bullet_list bullet="*">
                    <list_item>
                        <paragraph>in your <literal>Character control</literal> set you may have an action <literal>Jump</literal>,</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>in your <literal>Vehicle control</literal> set you may have an action <literal>Accelerate</literal>,</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>in your <literal>Menu</literal> set you may have an action <literal>Select</literal>.</paragraph>
                    </list_item>
                </bullet_list>
            </block_quote>
            <paragraph>All are bound to the trigger on your controller.</paragraph>
            <paragraph>OpenXR will only bind an input or output to a single action.
                If the same input or output is bound to multiple actions the one in the active action set
                with the highest priority will be the one updated/used.
                So in our above example it will thus be important that only one action set is active.</paragraph>
            <paragraph>For your first XR game/application we highly recommend starting with just
                a single action set and to not over-engineer things.</paragraph>
            <paragraph>For our walkthrough in this document we will thus create a single action set
                called <literal>my_first_action_set</literal>.
                We do this by pressing the <inline classes="role-button role-ui">Add action set</inline> button:</paragraph>
            <image candidates="{'*': 'tutorials/xr/img/xr_my_first_action_set.webp'}" original_uri="img/xr_my_first_action_set.webp" uri="tutorials/xr/img/xr_my_first_action_set.webp"></image>
            <paragraph>The columns in our table are as follows:</paragraph>
            <table classes="colwidths-given wrap-normal" width="100%">
                <tgroup cols="3">
                    <colspec colwidth="7"></colspec>
                    <colspec colwidth="23"></colspec>
                    <colspec colwidth="70"></colspec>
                    <thead>
                        <row>
                            <entry>
                                <paragraph>Col</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Value</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Description</paragraph>
                            </entry>
                        </row>
                    </thead>
                    <tbody>
                        <row>
                            <entry>
                                <paragraph>1</paragraph>
                            </entry>
                            <entry>
                                <paragraph>my_first_action_set</paragraph>
                            </entry>
                            <entry>
                                <paragraph>This is the internal name of the action set.
                                    OpenXR doesn't specify specific restrictions on this name other than size, however
                                    some XR runtimes will not like spaces or special characters.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>2</paragraph>
                            </entry>
                            <entry>
                                <paragraph>My first action set</paragraph>
                            </entry>
                            <entry>
                                <paragraph>This is a human-readable name for the action set.
                                    Some XR runtimes will display this name to the end user, for example in
                                    configuration dialogs.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>3</paragraph>
                            </entry>
                            <entry>
                                <paragraph>0</paragraph>
                            </entry>
                            <entry>
                                <paragraph>This is the priority of the action set.
                                    If multiple active action sets have actions bound to the same controller's inputs or
                                    outputs, the action set with the highest priority value will determine the action
                                    that is updated.</paragraph>
                            </entry>
                        </row>
                    </tbody>
                </tgroup>
            </table>
        </section>
        <section ids="actions" names="actions">
            <title>Actions</title>
            <paragraph>In the XR action map, actions are the entities that your game/application will
                interact with.
                For instance, we can define an action <literal>Shoot</literal> and the input bound to that action will
                trigger the <literal>button_pressed</literal> signal on the relevant <reference internal="True" refuri="../../classes/class_xrcontroller3d#class-xrcontroller3d"><inline classes="std std-ref">XRController3D</inline></reference>
                node in your scene with <literal>Shoot</literal> as the <literal>name</literal> parameter of the signal.</paragraph>
            <paragraph>You can also poll the current state of an action.
                <reference internal="True" refuri="../../classes/class_xrcontroller3d#class-xrcontroller3d"><inline classes="std std-ref">XRController3D</inline></reference> for instance has
                an <literal>is_button_pressed</literal> method.</paragraph>
            <paragraph>Actions can be used for both input and output and each action has a type that defines
                its behavior.</paragraph>
            <bullet_list bullet="*">
                <list_item>
                    <paragraph>The <literal>Bool</literal> type is used for discrete input like buttons.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>The <literal>Float</literal> type is used for analogue input like triggers.</paragraph>
                </list_item>
            </bullet_list>
            <paragraph>These two are special as they are the only ones that are interchangeable.
                OpenXR will handle conversions between <literal>Bool</literal> and <literal>Float</literal> inputs and actions.
                You can get the value of a <literal>Float</literal> type action by calling the method <literal>get_float</literal> on
                your <reference internal="True" refuri="../../classes/class_xrcontroller3d#class-xrcontroller3d"><inline classes="std std-ref">XRController3D</inline></reference> node.
                It emits the <literal>input_float_changed</literal> signal when changed.</paragraph>
            <note>
                <paragraph>Where analogue inputs are queried as buttons a threshold is applied.
                    This threshold is currently managed exclusively by the XR runtime.
                    There are plans to extend Godot to provide some level of control over these thresholds
                    in the future.</paragraph>
            </note>
            <paragraph>The <literal>Vector2</literal> type defines the input as an axis input.
                Touchpads, thumbsticks and similar inputs are exposed as vectors.
                You can get the value of a <literal>Vector2</literal> type action by calling the method <literal>get_vector2</literal>
                on your <reference internal="True" refuri="../../classes/class_xrcontroller3d#class-xrcontroller3d"><inline classes="std std-ref">XRController3D</inline></reference> node.
                It emits the <literal>input_vector2_changed</literal> signal when changed.</paragraph>
            <paragraph>The <literal>Pose</literal> type defines a spatially tracked input.
                Multiple "pose" inputs are available in OpenXR: <literal>aim</literal>, <literal>grip</literal> and <literal>palm</literal>.
                Your <reference internal="True" refuri="../../classes/class_xrcontroller3d#class-xrcontroller3d"><inline classes="std std-ref">XRController3D</inline></reference> node is automatically positioned based
                on the pose action assigned to <literal>pose</literal> property of this node.
                More about poses later.</paragraph>
            <note>
                <paragraph>The OpenXR implementation in Godot also exposes a special pose called <literal>Skeleton</literal>.
                    This is part of the hand tracking implementation.
                    This pose is exposed through the <literal>skeleton</literal> action that is supported outside of the
                    action map system.
                    It is thus always present if hand tracking is supported.
                    You don't need to bind actions to this pose to use it.</paragraph>
            </note>
            <paragraph>Finally, the only output type is <literal>Haptic</literal> and it allows us to set the intensity of
                haptic feedback, such as controller vibration.
                Controllers can have multiple haptic outputs and support for haptic vests is coming
                to OpenXR.</paragraph>
            <paragraph>So lets add an action for our aim pose, we do this by clicking on the <literal>+</literal> button for
                our action set:</paragraph>
            <image candidates="{'*': 'tutorials/xr/img/xr_aim_pose.webp'}" original_uri="img/xr_aim_pose.webp" uri="tutorials/xr/img/xr_aim_pose.webp"></image>
            <paragraph>The columns in our table are as follows:</paragraph>
            <table classes="colwidths-given wrap-normal" width="100%">
                <tgroup cols="3">
                    <colspec colwidth="7"></colspec>
                    <colspec colwidth="23"></colspec>
                    <colspec colwidth="70"></colspec>
                    <thead>
                        <row>
                            <entry>
                                <paragraph>Col</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Value</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Description</paragraph>
                            </entry>
                        </row>
                    </thead>
                    <tbody>
                        <row>
                            <entry>
                                <paragraph>1</paragraph>
                            </entry>
                            <entry>
                                <paragraph>aim_pose</paragraph>
                            </entry>
                            <entry>
                                <paragraph>This is the internal name of the action.
                                    OpenXR doesn't specify specific restrictions on this name other then size, however
                                    some XR runtimes will not like spaces or special characters.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>2</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Aim pose</paragraph>
                            </entry>
                            <entry>
                                <paragraph>This is a human-readable name for the action.
                                    Some XR runtimes will display this name to the end user, for example in
                                    configuration dialogs.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>3</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Pose</paragraph>
                            </entry>
                            <entry>
                                <paragraph>The type of this action.</paragraph>
                            </entry>
                        </row>
                    </tbody>
                </tgroup>
            </table>
            <paragraph>OpenXR defines a number of bindable input poses that are commonly available
                for controllers.
                There are no rules for which poses are supported for different controllers.
                The poses OpenXR currently defines are:</paragraph>
            <block_quote>
                <bullet_list bullet="*">
                    <list_item>
                        <paragraph>The aim pose on most controllers is positioned slightly in front of the controller
                            and aims forward.
                            This is a great pose to use for laser pointers or to align the muzzle of a weapon
                            with.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>The grip pose on most controllers is positioned where the grip button is placed on
                            the controller.
                            The orientation of this pose differs between controllers and can differ for the same
                            controller on different XR runtimes.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>The palm pose on most controllers is positioned in the center of the palm of the hand
                            holding the controller.
                            This is a new pose that is not available on all XR runtimes.</paragraph>
                    </list_item>
                </bullet_list>
            </block_quote>
            <note>
                <paragraph>If hand tracking is used, there are currently big differences in implementations
                    between the different XR runtimes.
                    As a result the action map is currently not suitable for hand tracking. Work is being
                    done on this so stay tuned.</paragraph>
            </note>
            <paragraph>Let's complete our list of actions for a very simple shooting game/application:</paragraph>
            <image candidates="{'*': 'tutorials/xr/img/xr_all_actions.webp'}" original_uri="img/xr_all_actions.webp" uri="tutorials/xr/img/xr_all_actions.webp"></image>
            <paragraph>The actions we have added are:</paragraph>
            <block_quote>
                <bullet_list bullet="*">
                    <list_item>
                        <paragraph>movement, which allows the user to move around outside of normal room scale tracking.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>grab, which detects that the user wants to hold something.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>shoot, which detects that the user wants to fire the weapon they are holding.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>haptic, which allows us to output haptic feedback.</paragraph>
                    </list_item>
                </bullet_list>
            </block_quote>
            <paragraph>Now note that we don't distinguish between the left and right hand.
                This is something that is determined at the next stage.
                We've implemented the action system in such a way that you can bind the same action
                to both hands.
                The appropriate <reference internal="True" refuri="../../classes/class_xrcontroller3d#class-xrcontroller3d"><inline classes="std std-ref">XRController3D</inline></reference> node will emit the signal.</paragraph>
            <warning>
                <paragraph>For both grab and shoot we've used the <literal>Bool</literal> type.
                    As mentioned before, OpenXR does automatic conversions from an analogue controls
                    however not all XR Runtimes currently apply sensible thresholds.</paragraph>
                <paragraph>We recommend as a workaround to use the <literal>Float</literal> type when interacting with triggers
                    and grip buttons and apply your own threshold.</paragraph>
                <paragraph>For buttons like A/B/X/Y and similar where there is no analogue option, the <literal>Bool</literal>
                    type works fine.</paragraph>
            </warning>
            <note>
                <paragraph>You can bind the same action to multiple inputs for the same controller on the same
                    profile.
                    In this case the XR runtime will attempt to combine the inputs.</paragraph>
                <bullet_list bullet="*">
                    <list_item>
                        <paragraph>For <literal>Bool</literal> inputs, this will perform an <literal>OR</literal> operation between the buttons.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>For <literal>Float</literal> inputs, this will take the highest value of the bound inputs.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>The behavior for <literal>Pose</literal> inputs is undefined, but the first bound input is likely to
                            be used.</paragraph>
                    </list_item>
                </bullet_list>
                <paragraph>You shouldn't bind multiple actions of the same action set to the same controller input.
                    If you do this, or if actions are bound from multiple action sets but they have
                    overlapping priorities, the behavior is undefined.
                    The XR runtime may simply not accept your action map, or it may take this on a first
                    come first serve basis.</paragraph>
                <paragraph>We are still investigating the restrictions around binding multiple actions to the same
                    output as this scenario makes sense.
                    The OpenXR specification seems to not allow this.</paragraph>
            </note>
            <paragraph>Now that we have our basic actions defined, it's time to hook them up.</paragraph>
        </section>
        <section ids="profiles" names="profiles">
            <title>Profiles</title>
            <paragraph>In OpenXR controller bindings are captured in so-called "Interaction Profiles".
                We've shortened it to "Profiles" because it takes up less space.</paragraph>
            <paragraph>This generic name is chosen because controllers don't cover the entire system.
                Currently there are also profiles for trackers, remotes and tracked pens.
                There are also provisions for devices such as treadmills, haptic vests and such even though those are not part of the specification yet.</paragraph>
            <warning>
                <paragraph>It is important to know that OpenXR has strict checking on supported devices.
                    The core specification identifies a number of controllers and similar devices with
                    their supported inputs and outputs.
                    Every XR runtime must accept these interaction profiles even if they aren't applicable.</paragraph>
                <paragraph>New devices are added through extensions and XR runtimes must specify which ones they
                    support.
                    XR runtimes that do not support a device added through extensions will not accept these
                    profiles.
                    XR runtimes that do not support added input or output types will often crash if
                    supplied.</paragraph>
                <paragraph>As such Godot keeps meta data of all available devices, their inputs and outputs and
                    which extension adds support for them.
                    You can create interaction profiles for all devices you wish to support.
                    Godot will filter out those not supported by the XR runtime the user is using.</paragraph>
                <paragraph>This does mean that in order to support new devices, you might need to update to a more
                    recent version of Godot.</paragraph>
            </warning>
            <paragraph>It is however also important to note that the action map has been designed
                with this in mind.
                When new devices enter the market, or when your users use devices that you
                do not have access to, the action map system relies on the XR runtime.
                It is the XR runtime's job to choose the best fitting interaction profile that has
                been specified and adapt it for the controller the user is using.</paragraph>
            <paragraph>How the XR runtime does this is left to the implementation of the runtime and there
                are thus vast differences between the runtimes.
                Some runtimes might even permit users to edit the bindings themselves.</paragraph>
            <paragraph>A common approach for a runtime is to look for a matching interaction profile first.
                If this is not found it will check the most common profiles such as that of
                the "Touch controller" and do a conversion.
                If all else fails, it will check the generic <reference internal="True" refid="doc-xr-action-map-simple"><inline classes="std std-ref">"Simple controller"</inline></reference>.</paragraph>
            <note>
                <paragraph>There is an important conclusion to be made here:
                    When a controller is found, and the action map is applied to it, the XR runtime is not
                    limited to the exact configurations you set up in Godot's action map editor.
                    While the runtime will generally choose a suitable mapping based on one of the bindings
                    you set up in the action map, it can deviate from it.</paragraph>
                <paragraph>For example, when the Touch controller profile is used any of the following scenarios
                    could be true:</paragraph>
                <block_quote>
                    <bullet_list bullet="*">
                        <list_item>
                            <paragraph>we could be using a Quest 1 controller,</paragraph>
                        </list_item>
                        <list_item>
                            <paragraph>we could be using a Quest 2 controller,</paragraph>
                        </list_item>
                        <list_item>
                            <paragraph>we could be using a Quest Pro controller but no Quest Pro profile was given or the
                                XR runtime being used does not support the Quest Pro controller,</paragraph>
                        </list_item>
                        <list_item>
                            <paragraph>it could be a completely different controller for which no profile was given but
                                the XR runtime is using the touch bindings as a base.</paragraph>
                        </list_item>
                    </bullet_list>
                </block_quote>
                <paragraph>Ergo, there currently is no way to know with certainty,
                    which controller the user is actually using.</paragraph>
            </note>
            <warning>
                <paragraph>Finally, and this trips up a lot of people, the bindings aren't set in stone.
                    It is fully allowed, and even expected, that an XR runtime allows a user
                    to customise the bindings.</paragraph>
                <paragraph>At the moment none of the XR runtimes offer this functionality though SteamVR has
                    an existing UI from OpenVRs action map system that is still accessible.
                    This is actively being worked on however.</paragraph>
            </warning>
        </section>
        <section ids="our-first-controller-binding" names="our\ first\ controller\ binding">
            <title>Our first controller binding</title>
            <paragraph>Let's set up our first controller binding, using the Touch controller as an example.</paragraph>
            <paragraph>Press "Add profile", find the Touch controller, and add it.
                If it is not in the list, then it may already have been added.</paragraph>
            <image candidates="{'*': 'tutorials/xr/img/xr_add_touch_controller.webp'}" original_uri="img/xr_add_touch_controller.webp" uri="tutorials/xr/img/xr_add_touch_controller.webp"></image>
            <paragraph>Our UI now shows panels for both the left and right controllers.
                The panels contain all of the possible inputs and outputs for each controller.
                We can use the <literal>+</literal> next to each entry to bind it to an action:</paragraph>
            <image candidates="{'*': 'tutorials/xr/img/xr_select_action.webp'}" original_uri="img/xr_select_action.webp" uri="tutorials/xr/img/xr_select_action.webp"></image>
            <paragraph>Let's finish our configuration:</paragraph>
            <image candidates="{'*': 'tutorials/xr/img/xr_touch_completed.webp'}" original_uri="img/xr_touch_completed.webp" uri="tutorials/xr/img/xr_touch_completed.webp"></image>
            <paragraph>Each action is bound the given input or output for both controllers to indicate that
                we support the action on either controller.
                The exception is the movement action which is bound only to the right hand controller.
                It is likely that we would want to use the left hand thumbstick for a different purpose,
                say a teleport function.</paragraph>
            <paragraph>In developing your game/application you have to account for the possibility that
                the user changes the binding and binds the movement to the left hand thumbstick.</paragraph>
            <paragraph>Also note that our shoot and grab boolean actions are linked to inputs of type <literal>Float</literal>.
                As mentioned before OpenXR will do conversions between the two, but do read the warning
                given on that subject earlier in this document.</paragraph>
            <note>
                <paragraph>Some of the inputs seem to appear in our list multiple times.</paragraph>
                <paragraph>For instance we can find the <literal>X</literal> button twice, once as <literal>X click</literal> and then
                    as <literal>X touch</literal>.
                    This is due to the Touch controller having a capacitive sensor.</paragraph>
                <bullet_list bullet="*">
                    <list_item>
                        <paragraph><literal>X touch</literal> will be true if the user is merely touching the X button.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph><literal>X click</literal> will be true when the user is actually pressing down on the button.</paragraph>
                    </list_item>
                </bullet_list>
                <paragraph>Similarly for the thumbstick we have:</paragraph>
                <bullet_list bullet="*">
                    <list_item>
                        <paragraph><literal>Thumbstick touch</literal> which will be true if the user is touching the thumbstick.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph><literal>Thumbstick</literal> which gives a value for the direction the thumbstick is pushed to.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph><literal>Thumbstick click</literal> which is true when the user is pressing down on the thumbstick.</paragraph>
                    </list_item>
                </bullet_list>
                <paragraph>It is important to note that only a select number of XR controllers support
                    touch sensors or have click features on thumbsticks.
                    Keep that in mind when designing your game/application.
                    Make sure these are used for optional features of your game/application.</paragraph>
            </note>
            <target refid="doc-xr-action-map-simple"></target>
        </section>
        <section ids="the-simple-controller doc-xr-action-map-simple" names="the\ simple\ controller doc_xr_action_map_simple">
            <title>The simple controller</title>
            <paragraph>The "Simple controller" is a generic controller that OpenXR offers as a fallback.
                We'll apply our mapping:</paragraph>
            <image candidates="{'*': 'tutorials/xr/img/xr_simple_controller.webp'}" original_uri="img/xr_simple_controller.webp" uri="tutorials/xr/img/xr_simple_controller.webp"></image>
            <paragraph>As becomes painfully clear, the simple controller is often far too simple
                and falls short for anything but the simplest of VR games/applications.</paragraph>
            <paragraph>This is why many XR runtimes only use it as a last resort and will attempt
                to use bindings from one of the more popular systems as a fallback first.</paragraph>
            <note>
                <paragraph>Due to the simple controller likely not covering the needs of your game,
                    it is tempting to provide bindings for every controller supported by OpenXR.
                    The default action map seems to suggest this as a valid course of action.
                    As mentioned before, the default action map was designed for ease of migration
                    from Godot 3.</paragraph>
                <paragraph>It is the recommendation from the OpenXR Working Group that only bindings
                    for controllers actually tested by the developer are setup.
                    The XR runtimes are designed with this in mind.
                    They can perform a better job of rebinding a provided binding than
                    a developer can make educated guesses.
                    Especially as the developer can't test if this leads to a comfortable experience
                    for the end user.</paragraph>
                <paragraph>This is our advice as well: limit your action map to the interaction profiles
                    for devices you have actually tested your game with.
                    The Oculus Touch controller is widely used as a fallback controller by many runtimes.
                    If you are able to test your game using a Meta Rift or Quest and add this profile
                    there is a high probability your game will work with other headsets.</paragraph>
            </note>
            <target refid="doc-binding-modifiers"></target>
        </section>
        <section ids="binding-modifiers doc-binding-modifiers" names="binding\ modifiers doc_binding_modifiers">
            <title>Binding Modifiers</title>
            <paragraph>One of the main goals of the action map is to remove the need for the application
                to know the hardware used.
                However, sometimes the hardware has physical differences that require inputs to
                be altered in ways other than how they are bound to actions.
                This need ranges from setting thresholds, to altering the inputs available
                on a controller.</paragraph>
            <paragraph>Binding modifiers are not enabled by default and require enabling in
                the OpenXR project settings.
                Also there is no guarantee that these modifiers are supported by every runtime.
                You will need to consult the support for the runtimes you are targeting
                and decide whether to rely on the modifiers or implement some form of fallback mechanism.</paragraph>
            <paragraph>If you are targeting multiple runtimes that have support for the same controllers,
                you may need to create separate action maps for each runtime.
                You can control which action map Godot uses by using different export templates
                for each runtime and using a custom <reference internal="True" refuri="../export/feature_tags#doc-feature-tags"><inline classes="std std-ref">feature tag</inline></reference>
                to set the action map.</paragraph>
            <paragraph>In Godot, binding modifiers are divided into two groups:
                modifiers that work on the interaction profile level,
                and modifiers that work on individual bindings.</paragraph>
            <section ids="binding-modifiers-on-an-interaction-profile" names="binding\ modifiers\ on\ an\ interaction\ profile">
                <title>Binding modifiers on an interaction profile</title>
                <paragraph>Binding modifiers that are applied to the whole interaction profile can be accessed
                    through the modifier button on the right side of the interaction profile editor.</paragraph>
                <image candidates="{'*': 'tutorials/xr/img/openxr_ip_binding_modifier.webp'}" original_uri="img/openxr_ip_binding_modifier.webp" uri="tutorials/xr/img/openxr_ip_binding_modifier.webp"></image>
                <paragraph>You can add a new modifier by pressing the <inline classes="role-button role-ui">Add binding modifier</inline> button.</paragraph>
                <warning>
                    <paragraph>As Godot doesn't know which controllers and runtimes support a modifier,
                        there is no restriction to adding modifiers.
                        Unsupported modifiers will be ignored.</paragraph>
                </warning>
                <section ids="dpad-binding-modifier" names="dpad\ binding\ modifier">
                    <title>Dpad Binding modifier</title>
                    <paragraph>The dpad binding modifier adds new inputs to an interaction profile for each joystick
                        and thumbpad input on this controller.
                        It turns the input into a dpad with separate up, down, left and right inputs
                        that are exposed as buttons:</paragraph>
                    <image candidates="{'*': 'tutorials/xr/img/openxr_thumbstick_dpad.webp'}" original_uri="img/openxr_thumbstick_dpad.webp" uri="tutorials/xr/img/openxr_thumbstick_dpad.webp"></image>
                    <note>
                        <paragraph>Inputs related to extensions are denoted with an asterix.</paragraph>
                    </note>
                    <paragraph>In order to use the dpad binding modifier you need to enable
                        the dpad binding modifier extension in project settings:</paragraph>
                    <image candidates="{'*': 'tutorials/xr/img/openxr_project_settings_dpad_modifier.webp'}" original_uri="img/openxr_project_settings_dpad_modifier.webp" uri="tutorials/xr/img/openxr_project_settings_dpad_modifier.webp"></image>
                    <paragraph>Enabling the extension is enough to make this functionality work using default settings.</paragraph>
                    <paragraph>Adding the modifier is optional and allows you to fine tune the way
                        the dpad functionality behaves.
                        You can add the modifier multiple times to set different settings for different inputs.</paragraph>
                    <image candidates="{'*': 'tutorials/xr/img/openxr_dpad_modifier.webp'}" original_uri="img/openxr_dpad_modifier.webp" uri="tutorials/xr/img/openxr_dpad_modifier.webp"></image>
                    <paragraph>These settings are used as follows:</paragraph>
                    <block_quote>
                        <bullet_list bullet="*">
                            <list_item>
                                <paragraph><literal>Action Set</literal> defines the action set to which these settings are applied.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>Input Path</literal> defines the original input that is mapped to the new dpad inputs.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>Threshold</literal> specifies the threshold value that will enable a dpad action,
                                    e.g. a value of <literal>0.6</literal> means that if the distance from center goes above <literal>0.6</literal>
                                    the dpad action is pressed.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>Threshold Released</literal> specifies the threshold value that will disable a dpad action,
                                    e.g. a value of <literal>0.4</literal> means that if the distance from center goes below <literal>0.4</literal>
                                    the dpad action is released.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>Center Region</literal> specifies the distance from center that enabled the center action,
                                    this is only supported for trackpads.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>Wedge Angle</literal> specifies the angle of each wedge.
                                    A value of <literal>90 degrees</literal> or lower means that up, down, left and right each have
                                    a separate slice in which they are in the pressed state.
                                    A value above <literal>90 degrees</literal> means that the slices overlap and that multiple
                                    actions can be in the pressed state.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>Is Sticky</literal>, when enabled means that an action stays in the pressed state until
                                    the thumbstick or trackpad moves into another wedge even if it has left the wedge
                                    for that action.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>On Haptic</literal> lets us define a haptic output that is automatically activated
                                    when an action becomes pressed.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>Off Haptic</literal> lets us define a haptic output that is automatically activated
                                    when an action is released.</paragraph>
                            </list_item>
                        </bullet_list>
                    </block_quote>
                </section>
            </section>
            <section ids="binding-modifiers-on-individual-bindings" names="binding\ modifiers\ on\ individual\ bindings">
                <title>Binding modifiers on individual bindings</title>
                <paragraph>Binding modifiers that are applied to individual bindings can be accessed through
                    the binding modifier button next to action attached to an input:</paragraph>
                <image candidates="{'*': 'tutorials/xr/img/openxr_action_binding_modifier.webp'}" original_uri="img/openxr_action_binding_modifier.webp" uri="tutorials/xr/img/openxr_action_binding_modifier.webp"></image>
                <paragraph>You can add a new modifier by pressing the <inline classes="role-button role-ui">Add binding modifier</inline> button.</paragraph>
                <warning>
                    <paragraph>As Godot doesn't know which inputs on each runtime support a modifier,
                        there is no restriction to adding modifiers.
                        If the modifier extension is unsupported, modifiers will be filtered out at runtime.
                        Modifiers added to the wrong input may result in a runtime error.</paragraph>
                    <paragraph>You should test your action map on the actual hardware and runtime to verify
                        the proper setup.</paragraph>
                </warning>
                <section ids="analog-threshold-modifier" names="analog\ threshold\ modifier">
                    <title>Analog threshold modifier</title>
                    <paragraph>The analog threshold modifier allows you to specify the thresholds used for any analog
                        input, like the trigger, that has a boolean input. This controls when the input is in
                        the pressed state.</paragraph>
                    <paragraph>In order to use this modifier you must enable the analog threshold extension in
                        the project settings:</paragraph>
                    <image candidates="{'*': 'tutorials/xr/img/openxr_project_settings_analog_threshold_modifier.webp'}" original_uri="img/openxr_project_settings_analog_threshold_modifier.webp" uri="tutorials/xr/img/openxr_project_settings_analog_threshold_modifier.webp"></image>
                    <paragraph>The analog threshold modifier has the following settings:</paragraph>
                    <image candidates="{'*': 'tutorials/xr/img/openxr_analog_threshold_modifier.webp'}" original_uri="img/openxr_analog_threshold_modifier.webp" uri="tutorials/xr/img/openxr_analog_threshold_modifier.webp"></image>
                    <paragraph>These are defined as follows:</paragraph>
                    <block_quote>
                        <bullet_list bullet="*">
                            <list_item>
                                <paragraph><literal>On Threshold</literal> specifies the threshold value that will enable the action,
                                    e.g. a value of <literal>0.6</literal> means that when the analog value gets above <literal>0.6</literal>
                                    the action is set to the pressed state.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>Off Threshold</literal> specifies the threshold value that will disable the action,
                                    e.g. a value of <literal>0.4</literal> means that when the analog value goes below <literal>0.4</literal>
                                    the action is set in to the released state.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>On Haptic</literal> lets us define a haptic output that is automatically activated
                                    when the input is pressed.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>Off Haptic</literal> lets us define a haptic output that is automatically activated
                                    when the input is released.</paragraph>
                            </list_item>
                        </bullet_list>
                    </block_quote>
                </section>
            </section>
            <section ids="haptics-on-modifiers" names="haptics\ on\ modifiers">
                <title>Haptics on modifiers</title>
                <paragraph>Modifiers can support automatic haptic output that is triggered when thresholds
                    are reached.</paragraph>
                <note>
                    <paragraph>Currently both available modifiers support this feature however there is no rule future
                        modifiers also have this capability.
                        Only one type of haptic feedback is supported but in the future other options
                        may become available.</paragraph>
                </note>
                <section ids="haptic-vibration" names="haptic\ vibration">
                    <title>Haptic vibration</title>
                    <paragraph>The haptic vibration allows us to specify a simple haptic pulse:</paragraph>
                    <image candidates="{'*': 'tutorials/xr/img/openxr_haptic_vibration.webp'}" original_uri="img/openxr_haptic_vibration.webp" uri="tutorials/xr/img/openxr_haptic_vibration.webp"></image>
                    <paragraph>It has the following options:</paragraph>
                    <block_quote>
                        <bullet_list bullet="*">
                            <list_item>
                                <paragraph><literal>Duration</literal> is the duration of the pulse in nanoseconds. <literal>-1</literal> lets the runtime
                                    choose an optimal value for a short pulse suitable for the current hardware.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>Frequency</literal> is the frequency of the pulse in Hz. <literal>0</literal> lets the runtime choose
                                    an optimal frequency for a short pulse suitable for the current hardware.</paragraph>
                            </list_item>
                            <list_item>
                                <paragraph><literal>Amplitude</literal> is the amplitude of the pulse.</paragraph>
                            </list_item>
                        </bullet_list>
                    </block_quote>
                    <substitution_definition names="weblate_widget"><reference refuri="https://hosted.weblate.org/engage/godot-engine/?utm_source=widget"><image alt="Translation status" candidates="{'?': 'https://hosted.weblate.org/widgets/godot-engine/-/godot-docs/287x66-white.png'}" height="66" uri="https://hosted.weblate.org/widgets/godot-engine/-/godot-docs/287x66-white.png" width="287"></image></reference></substitution_definition>
                </section>
            </section>
        </section>
    </section>
</document>
