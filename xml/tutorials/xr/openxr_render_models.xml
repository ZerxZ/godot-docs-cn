<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE document PUBLIC "+//IDN docutils.sourceforge.net//DTD Docutils Generic//EN//XML" "http://docutils.sourceforge.net/docs/ref/docutils.dtd">
<!-- Generated by Docutils 0.21.2 -->
<document source="/home/runner/work/godot-docs-cn/godot-docs-cn/godot-docs/docs/tutorials/xr/openxr_render_models.rst" translation_progress="{'total': 0, 'translated': 0}" xmlns:c="https://www.sphinx-doc.org/" xmlns:changeset="https://www.sphinx-doc.org/" xmlns:citation="https://www.sphinx-doc.org/" xmlns:cpp="https://www.sphinx-doc.org/" xmlns:index="https://www.sphinx-doc.org/" xmlns:js="https://www.sphinx-doc.org/" xmlns:math="https://www.sphinx-doc.org/" xmlns:py="https://www.sphinx-doc.org/" xmlns:rst="https://www.sphinx-doc.org/" xmlns:std="https://www.sphinx-doc.org/">
    <target refid="doc-openxr-render-models"></target>
    <section ids="openxr-render-models doc-openxr-render-models" names="openxr\ render\ models doc_openxr_render_models">
        <title>OpenXR Render Models</title>
        <paragraph>A cornerstone of OpenXR's API design is being as platform agnostic as possible.
            A great example of this is OpenXR's action map system where XR runtimes
            have to support core interaction profiles to fall back on,
            if no interaction profile exists for the hardware being used.
            This ensures that OpenXR applications keep functioning even when used on
            hardware that didn't exist when the application was released,
            or that the developers of the application did not have access too.</paragraph>
        <paragraph>A consequence of this is that the application developer doesn't know with any
            certainty what hardware is being used, as the XR runtime could be mimicking
            other hardware.
            The application developer thus can't show anything in relation to the actual
            hardware used, the most common use case being showing the controllers the user
            is currently holding.</paragraph>
        <paragraph>Showing the correct controller models and having these models
            correctly positioned is important to a proper sense of immersion.</paragraph>
        <paragraph>This is where OpenXR's <reference name="render models API" refuri="https://registry.khronos.org/OpenXR/specs/1.1/html/xrspec.html#XR_EXT_render_models">render models API</reference><target ids="render-models-api" names="render\ models\ api" refuri="https://registry.khronos.org/OpenXR/specs/1.1/html/xrspec.html#XR_EXT_render_models"></target> comes in.
            This API allows us to query the XR runtime for 3D assets that are correct
            for the physical hardware being used.
            The API also allows us to query the position of this hardware within the
            tracking volume and the correct positioning of subcomponents of this hardware.</paragraph>
        <paragraph>For instance, we can correctly position and animate the trigger or show buttons
            being pressed.</paragraph>
        <paragraph>For those runtimes that support the
            <reference name="controller data source for hand tracking" refuri="https://registry.khronos.org/OpenXR/specs/1.1/html/xrspec.html#XR_EXT_hand_tracking_data_source">controller data source for hand tracking</reference><target ids="controller-data-source-for-hand-tracking" names="controller\ data\ source\ for\ hand\ tracking" refuri="https://registry.khronos.org/OpenXR/specs/1.1/html/xrspec.html#XR_EXT_hand_tracking_data_source"></target>
            , we can also correctly position the user's fingers and hand according to the
            shape of the controller.
            Do note that this works in combination with the
            <reference name="hand joints motion range extension" refuri="https://registry.khronos.org/OpenXR/specs/1.1/html/xrspec.html#XR_EXT_hand_joints_motion_range">hand joints motion range extension</reference><target ids="hand-joints-motion-range-extension" names="hand\ joints\ motion\ range\ extension" refuri="https://registry.khronos.org/OpenXR/specs/1.1/html/xrspec.html#XR_EXT_hand_joints_motion_range"></target>
            to prevent clipping of the fingers.</paragraph>
        <section ids="openxr-render-models-node" names="openxr\ render\ models\ node">
            <title>OpenXR Render models node</title>
            <paragraph>The <reference internal="True" refuri="../../classes/class_openxrrendermodelmanager#class-openxrrendermodelmanager"><inline classes="std std-ref">OpenXRRenderModelManager</inline></reference>
                node can be used to automate most of the render models functionality.
                This node keeps track of the active render models currently made
                available by the XR runtime.</paragraph>
            <paragraph>It will create child nodes for each active render model resulting in
                that render model being displayed.</paragraph>
            <paragraph>This node must have an <reference internal="True" refuri="../../classes/class_xrorigin3d#class-xrorigin3d"><inline classes="std std-ref">XROrigin3D</inline></reference> node as an
                ancestor.</paragraph>
            <paragraph>If <literal>tracker</literal> is set to <literal>Any</literal> our node will show all render models
                currently being tracked. In this scenario this node must be a direct
                child of our <reference internal="True" refuri="../../classes/class_xrorigin3d#class-xrorigin3d"><inline classes="std std-ref">XROrigin3D</inline></reference> node.</paragraph>
            <paragraph>If <literal>tracker</literal> is set to <literal>None set</literal> our node will only show render
                models for which no tracker has been identified. In this scenario this
                node must also be a direct child of our
                <reference internal="True" refuri="../../classes/class_xrorigin3d#class-xrorigin3d"><inline classes="std std-ref">XROrigin3D</inline></reference> node.</paragraph>
            <paragraph>If <literal>tracker</literal> is set to <literal>Left Hand</literal> or <literal>Right Hand</literal> our node will
                only show render models related to our left or right hand respectively.
                In this scenario, our node can be placed deeper in the scene tree.</paragraph>
            <warning>
                <paragraph>For most XR runtimes this means the render model represents a controller
                    that is actually being held by the user but this is not a guarantee.
                    Some XR runtimes will always set the tracker to either the left or right
                    hand even if the controller is not currently held but is being tracked.
                    You should always test this as this will lead to unwanted behavior.</paragraph>
            </warning>
            <paragraph>In this scenario we can also specify an action for a pose in the action map
                by setting the <literal>make_local_to_pose</literal> property to the pose action.
                Use this in combination with an <reference internal="True" refuri="../../classes/class_xrcontroller3d#class-xrcontroller3d"><inline classes="std std-ref">XRController3D</inline></reference>
                node that is using the same pose and you can now add a layer that allows
                you to deviate from the tracked position of both your controller and the
                related render model (see example below).</paragraph>
            <note>
                <paragraph>Combining the above with hand tracking does introduce the problem
                    that hand tracking is completely independent from the action map
                    system. You will need to combine the hand tracking and controller
                    tracking poses to properly offset the render models.</paragraph>
                <paragraph>This falls beyond the scope of this documentation.</paragraph>
            </note>
            <section ids="render-model-manager-example" names="render\ model\ manager\ example">
                <title>Render model manager example</title>
                <paragraph>You can download <reference name="our render models demo" refuri="https://github.com/godotengine/godot-demo-projects/tree/master/xr/openxr_render_models">our render models demo</reference><target ids="our-render-models-demo" names="our\ render\ models\ demo" refuri="https://github.com/godotengine/godot-demo-projects/tree/master/xr/openxr_render_models"></target>
                    which implements the setup described below.</paragraph>
                <image candidates="{'*': 'tutorials/xr/img/openxr_render_models_setup.webp'}" original_uri="img/openxr_render_models_setup.webp" uri="tutorials/xr/img/openxr_render_models_setup.webp"></image>
                <paragraph>In this setup we find an <reference internal="True" refuri="../../classes/class_openxrrendermodelmanager#class-openxrrendermodelmanager"><inline classes="std std-ref">OpenXRRenderModelManager</inline></reference>
                    node directly underneath our <reference internal="True" refuri="../../classes/class_xrorigin3d#class-xrorigin3d"><inline classes="std std-ref">XROrigin3D</inline></reference> node.
                    On this node our <literal>target</literal> property is set to <literal>None set</literal> and will handle
                    showing all render models that are currently not related to our left or
                    right hand controllers.</paragraph>
                <paragraph>We then see the same setup for our left and right hand so we'll focus on
                    just the left hand.</paragraph>
                <paragraph>We have an <reference internal="True" refuri="../../classes/class_xrcontroller3d#class-xrcontroller3d"><inline classes="std std-ref">XRController3D</inline></reference> that will track the
                    location of our hand.</paragraph>
                <note>
                    <paragraph>We are using the <literal>grip</literal> pose in this example. The <literal>palm</literal> pose is
                        arguably more suitable and predictable however it is not supported
                        by all XR runtimes. See the hand tracking demo project for a
                        solution to switching between these poses based on what is supported.</paragraph>
                </note>
                <paragraph>As a child of the node we have an <reference internal="True" refuri="../../classes/class_animatablebody3d#class-animatablebody3d"><inline classes="std std-ref">AnimatableBody3D</inline></reference>
                    node that follows the tracked location of the hand <strong>but</strong> will interact
                    with physics objects to stop the player's hand from going through walls etc.
                    This node has a collision shape that encapsulates the hand.</paragraph>
                <note>
                    <paragraph>It is important to set the physics priority so that this logic runs
                        after any physics logic that moves the XROrigin3D node or the hand
                        will lag a frame behind.</paragraph>
                </note>
                <paragraph>The script below shows a basic implementation for this that you can build
                    upon.</paragraph>
                <literal_block force="False" highlight_args="{}" language="gdscript" linenos="False" xml:space="preserve">class_name CollisionHands3D
extends AnimatableBody3D

func _ready():
    # Make sure these are set correctly.
    top_level = true
    sync_to_physics = false
    process_physics_priority = -90

func _physics_process(_delta):
    # Follow our parent node around.
    var dest_transform = get_parent().global_transform

    # We just apply rotation for this example.
    global_basis = dest_transform.basis

    # Attempt to move to where our tracked hand is.
    move_and_collide(dest_transform.origin - global_position)</literal_block>
                <paragraph>Finally we see another <reference internal="True" refuri="../../classes/class_openxrrendermodelmanager#class-openxrrendermodelmanager"><inline classes="std std-ref">OpenXRRenderModelManager</inline></reference>
                    node, this one with <literal>target</literal> set to the appropriate hand and
                    <literal>make_local_to_pose</literal> set to the correct pose.
                    This will ensure that the render models related to this hand are properly
                    shown and offset if our collision handler has altered the location.</paragraph>
                <raw format="html" xml:space="preserve">&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;"&gt;
    &lt;iframe src="https://www.youtube-nocookie.com/embed/_gNOd7wQ62M" frameborder="0" allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"&gt;&lt;/iframe&gt;
&lt;/div&gt;</raw>
            </section>
        </section>
        <section ids="render-model-node" names="render\ model\ node">
            <title>Render model node</title>
            <paragraph>The <reference internal="True" refuri="../../classes/class_openxrrendermodel#class-openxrrendermodel"><inline classes="std std-ref">OpenXRRenderModel</inline></reference> node implements
                all the logic to display and position a given render model provided by
                the render models API.</paragraph>
            <paragraph>Instances of this node are added by the render model manager node we used up
                above but you can interact with these directly if you wish.</paragraph>
            <paragraph>Whenever Godot obtains information about a new render model an RID is
                created to reference that render model.</paragraph>
            <paragraph>By assigning that RID to the <literal>render_model</literal> property on this node,
                the node will start displaying the render model and manage both the
                transform that places the render model in the correct place and
                animates all the sub objects.</paragraph>
            <paragraph>The <literal>get_top_level_path</literal> function will return the top level path
                associated with this render model. This will point to either the
                left or right hand. As the top level path can be set or cleared
                depending on whether the user picks up, or puts down, the controller
                you can connect to the <literal>render_model_top_level_path_changes</literal> signal
                and react to these changes.</paragraph>
            <paragraph>Depending on your setup of the
                <reference internal="True" refuri="../../classes/class_openxrrendermodelmanager#class-openxrrendermodelmanager"><inline classes="std std-ref">OpenXRRenderModelManager</inline></reference> nodes,
                render models will be removed or added as their top level path changes.</paragraph>
        </section>
        <section ids="backend-access" names="backend\ access">
            <title>Backend access</title>
            <paragraph>The nodes we've detailed out above handle all the display logic
                for us but it is possible to interact with the data that drives
                this directly and create your own implementation.</paragraph>
            <paragraph>For this you can access the
                <reference internal="True" refuri="../../classes/class_openxrrendermodelextension#class-openxrrendermodelextension"><inline classes="std std-ref">OpenXRRenderModelExtension</inline></reference>
                singleton.</paragraph>
            <paragraph>This object also lets you query whether render models are
                supported and enabled on the device currently being used by
                calling the <literal>is_active</literal> function on this object.</paragraph>
            <paragraph>The built-in logic implements the
                <reference name="interaction render model API" refuri="https://registry.khronos.org/OpenXR/specs/1.1/html/xrspec.html#XR_EXT_interaction_render_model">interaction render model API</reference><target ids="interaction-render-model-api" names="interaction\ render\ model\ api" refuri="https://registry.khronos.org/OpenXR/specs/1.1/html/xrspec.html#XR_EXT_interaction_render_model"></target>
                that lists all render models related to controllers and similar
                devices that are present in the action map.
                It will automatically create and remove render model entities
                that are exposed through this API.</paragraph>
            <paragraph>As other extensions become available these can be implemented
                in a GDExtension plugin. Such a plugin can call
                <literal>render_model_create</literal> and <literal>render_model_destroy</literal> to
                create the object that will provide access to that render
                model through the core render models API.</paragraph>
            <paragraph>You should not destroy a render model outside of this logic.</paragraph>
            <paragraph>You can connect to the <literal>render_model_added</literal> and
                <literal>render_model_removed</literal> signals to be informed when new render
                models are added or removed.</paragraph>
            <paragraph>The core methods for working with this API are listed
                below:</paragraph>
            <table ids="id1">
                <title>Render modele extension functions</title>
                <tgroup cols="2">
                    <colspec colwidth="50"></colspec>
                    <colspec colwidth="50"></colspec>
                    <thead>
                        <row>
                            <entry>
                                <paragraph>Function</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Description</paragraph>
                            </entry>
                        </row>
                    </thead>
                    <tbody>
                        <row>
                            <entry>
                                <paragraph>render_model_get_all</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Provides an array of RIDs for all render models
                                    that are being tracked.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>render_model_new_scene_instance</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Provides a new scene that contains all meshes
                                    needed to display the render model.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>render_model_get_subaction_paths</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Provides a list of subaction paths from your
                                    action map related to this render mode.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>render_model_get_top_level_path</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Returns the top level path associated with this
                                    render model (if any).
                                    Use the <literal>render_model_top_level_path_changed</literal>
                                    signal to react to this changing.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>render_model_get_confidence</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Returns the tracking confidence for the tracking
                                    data for this render model.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>render_model_get_root_transform</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Returns the root transform for this render model
                                    within our current reference space. This can be
                                    used to place the render model in space.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>render_model_get_animatable_node_count</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Returns the number of nodes in our render model
                                    scene that can be animated</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>render_model_get_animatable_node_name</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Returns the name of the node that we can animate.
                                    Note that this node can be any number of levels
                                    deep within the scene.</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>render_model_is_animatable_node_visible</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Returns true if this animatable node should be
                                    visible</paragraph>
                            </entry>
                        </row>
                        <row>
                            <entry>
                                <paragraph>render_model_get_animatable_node_transform</paragraph>
                            </entry>
                            <entry>
                                <paragraph>Returns the transform for this animatable node.
                                    This is a local transform that can be directly
                                    applied.</paragraph>
                            </entry>
                        </row>
                    </tbody>
                </tgroup>
            </table>
            <substitution_definition names="weblate_widget"><reference refuri="https://hosted.weblate.org/engage/godot-engine/?utm_source=widget"><image alt="Translation status" candidates="{'?': 'https://hosted.weblate.org/widgets/godot-engine/-/godot-docs/287x66-white.png'}" height="66" uri="https://hosted.weblate.org/widgets/godot-engine/-/godot-docs/287x66-white.png" width="287"></image></reference></substitution_definition>
        </section>
    </section>
</document>
