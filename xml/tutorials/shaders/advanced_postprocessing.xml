<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE document PUBLIC "+//IDN docutils.sourceforge.net//DTD Docutils Generic//EN//XML" "http://docutils.sourceforge.net/docs/ref/docutils.dtd">
<!-- Generated by Docutils 0.21.2 -->
<document source="/home/runner/work/godot-docs-cn/godot-docs-cn/godot-docs/docs/tutorials/shaders/advanced_postprocessing.rst" translation_progress="{'total': 0, 'translated': 0}" xmlns:c="https://www.sphinx-doc.org/" xmlns:changeset="https://www.sphinx-doc.org/" xmlns:citation="https://www.sphinx-doc.org/" xmlns:cpp="https://www.sphinx-doc.org/" xmlns:index="https://www.sphinx-doc.org/" xmlns:js="https://www.sphinx-doc.org/" xmlns:math="https://www.sphinx-doc.org/" xmlns:py="https://www.sphinx-doc.org/" xmlns:rst="https://www.sphinx-doc.org/" xmlns:std="https://www.sphinx-doc.org/">
    <target refid="doc-advanced-postprocessing"></target>
    <section ids="advanced-post-processing doc-advanced-postprocessing" names="advanced\ post-processing doc_advanced_postprocessing">
        <title>Advanced post-processing</title>
        <section ids="introduction" names="introduction">
            <title>Introduction</title>
            <paragraph>This tutorial describes an advanced method for post-processing in Godot.
                In particular, it will explain how to write a post-processing shader that
                uses the depth buffer. You should already be familiar with post-processing
                generally and, in particular, with the methods outlined in the <reference internal="True" refuri="custom_postprocessing#doc-custom-postprocessing"><inline classes="std std-ref">custom post-processing tutorial</inline></reference>.</paragraph>
        </section>
        <section ids="full-screen-quad" names="full\ screen\ quad">
            <title>Full screen quad</title>
            <paragraph>One way to make custom post-processing effects is by using a viewport. However,
                there are two main drawbacks of using a Viewport:</paragraph>
            <enumerated_list enumtype="arabic" prefix="" suffix=".">
                <list_item>
                    <paragraph>The depth buffer cannot be accessed</paragraph>
                </list_item>
                <list_item>
                    <paragraph>The effect of the post-processing shader is not visible in the editor</paragraph>
                </list_item>
            </enumerated_list>
            <paragraph>To get around the limitation on using the depth buffer, use a <reference internal="True" refuri="../../classes/class_meshinstance3d#class-meshinstance3d"><inline classes="std std-ref">MeshInstance3D</inline></reference>
                with a <reference internal="True" refuri="../../classes/class_quadmesh#class-quadmesh"><inline classes="std std-ref">QuadMesh</inline></reference> primitive. This allows us to use a
                shader and to access the depth texture of the scene. Next, use a vertex shader
                to make the quad cover the screen at all times so that the post-processing
                effect will be applied at all times, including in the editor.</paragraph>
            <paragraph>First, create a new MeshInstance3D and set its mesh to a QuadMesh. This creates
                a quad centered at position <literal>(0, 0, 0)</literal> with a width and height of <literal>1</literal>. Set
                the width and height to <literal>2</literal> and enable <strong>Flip Faces</strong>. Right now, the quad
                occupies a position in world space at the origin. However, we want it to move
                with the camera so that it always covers the entire screen. To do this, we will
                bypass the coordinate transforms that translate the vertex positions through the
                difference coordinate spaces and treat the vertices as if they were already in
                clip space.</paragraph>
            <paragraph>The vertex shader expects coordinates to be output in clip space, which are coordinates
                ranging from <literal>-1</literal> at the left and bottom of the screen to <literal>1</literal> at the top and right
                of the screen. This is why the QuadMesh needs to have height and width of <literal>2</literal>.
                Godot handles the transform from model to view space to clip space behind the scenes,
                so we need to nullify the effects of Godot's transformations. We do this by setting the
                <literal>POSITION</literal> built-in to our desired position. <literal>POSITION</literal> bypasses the built-in transformations
                and sets the vertex position in clip space directly.</paragraph>
            <literal_block force="False" highlight_args="{}" language="glsl" linenos="False" xml:space="preserve">shader_type spatial;
// Prevent the quad from being affected by lighting and fog. This also improves performance.
render_mode unshaded, fog_disabled;

void vertex() {
  POSITION = vec4(VERTEX.xy, 1.0, 1.0);
}</literal_block>
            <note>
                <paragraph>In versions of Godot earlier than 4.3, this code recommended using <literal>POSITION = vec4(VERTEX, 1.0);</literal>
                    which implicitly assumed the clip-space near plane was at <literal>0.0</literal>.
                    That code is now incorrect and will not work in versions 4.3+ as we
                    use a "reversed-z" depth buffer now where the near plane is at <literal>1.0</literal>.</paragraph>
            </note>
            <paragraph>Even with this vertex shader, the quad keeps disappearing. This is due to frustum
                culling, which is done on the CPU. Frustum culling uses the camera matrix and the
                AABBs of Meshes to determine if the Mesh will be visible <emphasis>before</emphasis> passing it to the GPU.
                The CPU has no knowledge of what we are doing with the vertices, so it assumes the
                coordinates specified refer to world positions, not clip space positions, which results
                in Godot culling the quad when we turn away from the center of the scene. In
                order to keep the quad from being culled, there are a few options:</paragraph>
            <enumerated_list enumtype="arabic" prefix="" suffix=".">
                <list_item>
                    <paragraph>Add the QuadMesh as a child to the camera, so the camera is always pointed at it</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Set the Geometry property <literal>extra_cull_margin</literal> as large as possible in the QuadMesh</paragraph>
                </list_item>
            </enumerated_list>
            <paragraph>The second option ensures that the quad is visible in the editor, while the first
                option guarantees that it will still be visible even if the camera moves outside the cull margin.
                You can also use both options.</paragraph>
        </section>
        <section ids="depth-texture" names="depth\ texture">
            <title>Depth texture</title>
            <paragraph>To read from the depth texture, we first need to create a texture uniform set to the depth buffer
                by using <literal>hint_depth_texture</literal>.</paragraph>
            <literal_block force="False" highlight_args="{}" language="glsl" linenos="False" xml:space="preserve">uniform sampler2D depth_texture : hint_depth_texture;</literal_block>
            <paragraph>Once defined, the depth texture can be read with the <literal>texture()</literal> function.</paragraph>
            <literal_block force="False" highlight_args="{}" language="glsl" linenos="False" xml:space="preserve">float depth = texture(depth_texture, SCREEN_UV).x;</literal_block>
            <note>
                <paragraph>Similar to accessing the screen texture, accessing the depth texture is only
                    possible when reading from the current viewport. The depth texture cannot be
                    accessed from another viewport to which you have rendered.</paragraph>
            </note>
            <paragraph>The values returned by <literal>depth_texture</literal> are between <literal>1.0</literal> and <literal>0.0</literal> (corresponding to
                the near and far plane, respectively, because of using a "reverse-z" depth buffer) and are nonlinear.
                When displaying depth directly from the <literal>depth_texture</literal>, everything will look almost
                black unless it is very close due to that nonlinearity. In order to make the depth value align with world or
                model coordinates, we need to linearize the value. When we apply the projection matrix to the
                vertex position, the z value is made nonlinear, so to linearize it, we multiply it by the
                inverse of the projection matrix, which in Godot, is accessible with the variable
                <literal>INV_PROJECTION_MATRIX</literal>.</paragraph>
            <paragraph>Firstly, take the screen space coordinates and transform them into normalized device
                coordinates (NDC). NDC run <literal>-1.0</literal> to <literal>1.0</literal> in <literal>x</literal> and <literal>y</literal> directions and
                from <literal>0.0</literal> to <literal>1.0</literal> in the <literal>z</literal> direction when using the Vulkan backend.
                Reconstruct the NDC using <literal>SCREEN_UV</literal> for the <literal>x</literal> and <literal>y</literal> axis, and
                the depth value for <literal>z</literal>.</paragraph>
            <literal_block force="False" highlight_args="{}" language="glsl" linenos="False" xml:space="preserve">void fragment() {
  float depth = texture(depth_texture, SCREEN_UV).x;
  vec3 ndc = vec3(SCREEN_UV * 2.0 - 1.0, depth);
}</literal_block>
            <note>
                <paragraph>This tutorial assumes the use of the Forward+ or Mobile renderers, which both
                    use Vulkan NDCs with a Z-range of <literal>[0.0, 1.0]</literal>. In contrast, the Compatibility
                    renderer uses OpenGL NDCs with a Z-range of <literal>[-1.0, 1.0]</literal>. For the Compatibility
                    renderer, replace the NDC calculation with this instead:</paragraph>
                <literal_block force="False" highlight_args="{}" language="glsl" linenos="False" xml:space="preserve">vec3 ndc = vec3(SCREEN_UV, depth) * 2.0 - 1.0;</literal_block>
                <paragraph>You can also use the <literal>CURRENT_RENDERER</literal> and <literal>RENDERER_COMPATIBILITY</literal>
                    built-in defines for a shader that will work in all renderers:</paragraph>
                <literal_block force="False" highlight_args="{}" language="glsl" linenos="False" xml:space="preserve">#if CURRENT_RENDERER == RENDERER_COMPATIBILITY
vec3 ndc = vec3(SCREEN_UV, depth) * 2.0 - 1.0;
#else
vec3 ndc = vec3(SCREEN_UV * 2.0 - 1.0, depth);
#endif</literal_block>
            </note>
            <paragraph>Convert NDC to view space by multiplying the NDC by <literal>INV_PROJECTION_MATRIX</literal>.
                Recall that view space gives positions relative to the camera, so the <literal>z</literal> value will give us
                the distance to the point.</paragraph>
            <literal_block force="False" highlight_args="{}" language="glsl" linenos="False" xml:space="preserve">void fragment() {
  ...
  vec4 view = INV_PROJECTION_MATRIX * vec4(ndc, 1.0);
  view.xyz /= view.w;
  float linear_depth = -view.z;
}</literal_block>
            <paragraph>Because the camera is facing the negative <literal>z</literal> direction, the position will have a negative <literal>z</literal> value.
                In order to get a usable depth value, we have to negate <literal>view.z</literal>.</paragraph>
            <paragraph>The world position can be constructed from the depth buffer using the following code, using the
                <literal>INV_VIEW_MATRIX</literal> to transform the position from view space into world space.</paragraph>
            <literal_block force="False" highlight_args="{}" language="glsl" linenos="False" xml:space="preserve">void fragment() {
  ...
  vec4 world = INV_VIEW_MATRIX * INV_PROJECTION_MATRIX * vec4(ndc, 1.0);
  vec3 world_position = world.xyz / world.w;
}</literal_block>
        </section>
        <section ids="example-shader" names="example\ shader">
            <title>Example shader</title>
            <paragraph>Once we add a line to output to <literal>ALBEDO</literal>, we have a complete shader that looks something like this.
                This shader lets you visualize the linear depth or world space coordinates, depending on which
                line is commented out.</paragraph>
            <literal_block force="False" highlight_args="{}" language="glsl" linenos="False" xml:space="preserve">shader_type spatial;
// Prevent the quad from being affected by lighting and fog. This also improves performance.
render_mode unshaded, fog_disabled;

uniform sampler2D depth_texture : hint_depth_texture;

void vertex() {
  POSITION = vec4(VERTEX.xy, 1.0, 1.0);
}

void fragment() {
  float depth = texture(depth_texture, SCREEN_UV).x;
  vec3 ndc = vec3(SCREEN_UV * 2.0 - 1.0, depth);
  vec4 view = INV_PROJECTION_MATRIX * vec4(ndc, 1.0);
  view.xyz /= view.w;
  float linear_depth = -view.z;

  vec4 world = INV_VIEW_MATRIX * INV_PROJECTION_MATRIX * vec4(ndc, 1.0);
  vec3 world_position = world.xyz / world.w;

  // Visualize linear depth
  ALBEDO.rgb = vec3(fract(linear_depth));

  // Visualize world coordinates
  //ALBEDO.rgb = fract(world_position).xyz;
}</literal_block>
        </section>
        <section ids="an-optimization" names="an\ optimization">
            <title>An optimization</title>
            <paragraph>You can benefit from using a single large triangle rather than using a full
                screen quad. The reason for this is explained <reference name="here" refuri="https://michaldrobot.com/2014/04/01/gcn-execution-patterns-in-full-screen-passes">here</reference><target ids="here" names="here" refuri="https://michaldrobot.com/2014/04/01/gcn-execution-patterns-in-full-screen-passes"></target>.
                However, the benefit is quite small and only beneficial when running especially
                complex fragment shaders.</paragraph>
            <paragraph>Set the Mesh in the MeshInstance3D to an <reference internal="True" refuri="../../classes/class_arraymesh#class-arraymesh"><inline classes="std std-ref">ArrayMesh</inline></reference>. An
                ArrayMesh is a tool that allows you to easily construct a Mesh from Arrays for
                vertices, normals, colors, etc.</paragraph>
            <paragraph>Now, attach a script to the MeshInstance3D and use the following code:</paragraph>
            <literal_block force="False" language="gdscript" linenos="False" xml:space="preserve">extends MeshInstance3D

func _ready():
  # Create a single triangle out of vertices:
  var verts = PackedVector3Array()
  verts.append(Vector3(-1.0, -1.0, 0.0))
  verts.append(Vector3(3.0, -1.0, 0.0))
  verts.append(Vector3(-1.0, 3.0, 0.0))

  # Create an array of arrays.
  # This could contain normals, colors, UVs, etc.
  var mesh_array = []
  mesh_array.resize(Mesh.ARRAY_MAX) #required size for ArrayMesh Array
  mesh_array[Mesh.ARRAY_VERTEX] = verts #position of vertex array in ArrayMesh Array

  # Create mesh from mesh_array:
  mesh.add_surface_from_arrays(Mesh.PRIMITIVE_TRIANGLES, mesh_array)</literal_block>
            <note>
                <paragraph>The triangle is specified in normalized device coordinates.
                    Recall, NDC run from <literal>-1.0</literal> to <literal>1.0</literal> in both the <literal>x</literal> and <literal>y</literal>
                    directions. This makes the screen <literal>2</literal> units wide and <literal>2</literal> units
                    tall. In order to cover the entire screen with a single triangle, use
                    a triangle that is <literal>4</literal> units wide and <literal>4</literal> units tall, double its
                    height and width.</paragraph>
            </note>
            <paragraph>Assign the same vertex shader from above and everything should look exactly the same.</paragraph>
            <paragraph>The one drawback to using an ArrayMesh over using a QuadMesh is that the ArrayMesh
                is not visible in the editor because the triangle is not constructed until the scene
                is run. To get around that, construct a single triangle Mesh in a modeling program
                and use that in the MeshInstance3D instead.</paragraph>
            <substitution_definition names="weblate_widget"><reference refuri="https://hosted.weblate.org/engage/godot-engine/?utm_source=widget"><image alt="Translation status" candidates="{'?': 'https://hosted.weblate.org/widgets/godot-engine/-/godot-docs/287x66-white.png'}" height="66" uri="https://hosted.weblate.org/widgets/godot-engine/-/godot-docs/287x66-white.png" width="287"></image></reference></substitution_definition>
        </section>
    </section>
</document>
