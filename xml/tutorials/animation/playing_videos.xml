<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE document PUBLIC "+//IDN docutils.sourceforge.net//DTD Docutils Generic//EN//XML" "http://docutils.sourceforge.net/docs/ref/docutils.dtd">
<!-- Generated by Docutils 0.21.2 -->
<document source="/home/runner/work/godot-docs-cn/godot-docs-cn/godot-docs/docs/tutorials/animation/playing_videos.rst" translation_progress="{'total': 0, 'translated': 0}" xmlns:c="https://www.sphinx-doc.org/" xmlns:changeset="https://www.sphinx-doc.org/" xmlns:citation="https://www.sphinx-doc.org/" xmlns:cpp="https://www.sphinx-doc.org/" xmlns:index="https://www.sphinx-doc.org/" xmlns:js="https://www.sphinx-doc.org/" xmlns:math="https://www.sphinx-doc.org/" xmlns:py="https://www.sphinx-doc.org/" xmlns:rst="https://www.sphinx-doc.org/" xmlns:std="https://www.sphinx-doc.org/">
    <target refid="doc-playing-videos"></target>
    <section ids="playing-videos doc-playing-videos" names="playing\ videos doc_playing_videos">
        <title>Playing videos</title>
        <paragraph>Godot supports video playback with the <reference internal="True" refuri="../../classes/class_videostreamplayer#class-videostreamplayer"><inline classes="std std-ref">VideoStreamPlayer</inline></reference> node.</paragraph>
        <section ids="supported-playback-formats" names="supported\ playback\ formats">
            <title>Supported playback formats</title>
            <paragraph>The only supported format in core is <strong>Ogg Theora</strong> (not to be confused with
                Ogg Vorbis audio) with optional Ogg Vorbis audio tracks. It's possible for
                extensions to bring support for additional formats.</paragraph>
            <paragraph>H.264 and H.265 cannot be supported in core Godot, as they are both encumbered
                by software patents. AV1 is royalty-free, but it remains slow to decode on the
                CPU and hardware decoding support isn't readily available on all GPUs in use
                yet.</paragraph>
            <paragraph>WebM was supported in core in Godot 3.x, but support for it was removed in 4.0
                as it was too buggy and difficult to maintain.</paragraph>
            <note>
                <paragraph>You may find videos with a <literal>.ogg</literal> or <literal>.ogx</literal> extensions, which are generic
                    extensions for data within an Ogg container.</paragraph>
                <paragraph>Renaming these file extensions to <literal>.ogv</literal> <emphasis>may</emphasis> allow the videos to be
                    imported in Godot. However, not all files with <literal>.ogg</literal> or <literal>.ogx</literal>
                    extensions are videos - some of them may only contain audio.</paragraph>
            </note>
        </section>
        <section ids="setting-up-videostreamplayer" names="setting\ up\ videostreamplayer">
            <title>Setting up VideoStreamPlayer</title>
            <enumerated_list enumtype="arabic" prefix="" suffix=".">
                <list_item>
                    <paragraph>Create a VideoStreamPlayer node using the Create New Node dialog.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Select the VideoStreamPlayer node in the scene tree dock, go to the inspector
                        and load a <literal>.ogv</literal> file in the Stream property.</paragraph>
                    <bullet_list bullet="-">
                        <list_item>
                            <paragraph>If you don't have your video in Ogg Theora format yet, jump to
                                <reference internal="True" refid="doc-playing-videos-recommended-theora-encoding-settings"><inline classes="std std-ref">Recommended Theora encoding settings</inline></reference>.</paragraph>
                        </list_item>
                    </bullet_list>
                </list_item>
                <list_item>
                    <paragraph>If you want the video to play as soon as the scene is loaded, check
                        <strong>Autoplay</strong> in the inspector. If not, leave <strong>Autoplay</strong> disabled and call
                        <literal>play()</literal> on the VideoStreamPlayer node in a script to start playback when
                        desired.</paragraph>
                </list_item>
            </enumerated_list>
            <section ids="handling-resizing-and-different-aspect-ratios" names="handling\ resizing\ and\ different\ aspect\ ratios">
                <title>Handling resizing and different aspect ratios</title>
                <paragraph>By default, the VideoStreamPlayer will automatically be resized to match
                    the video's resolution. You can make it follow usual <reference internal="True" refuri="../../classes/class_control#class-control"><inline classes="std std-ref">Control</inline></reference> sizing
                    by enabling <strong>Expand</strong> on the VideoStreamPlayer node.</paragraph>
                <paragraph>To adjust how the VideoStreamPlayer node resizes depending on window size,
                    adjust the anchors using the <strong>Layout</strong> menu at the top of the 2D editor
                    viewport. However, this setup may not be powerful enough to handle all use
                    cases, such as playing fullscreen videos without distorting the video (but with
                    empty space on the edges instead). For more control, you can use an
                    <reference internal="True" refuri="../../classes/class_aspectratiocontainer#class-aspectratiocontainer"><inline classes="std std-ref">AspectRatioContainer</inline></reference> node, which is designed to handle this kind of
                    use case:</paragraph>
                <paragraph>Add an AspectRatioContainer node. Make sure it is not a child of any other
                    container node. Select the AspectRatioContainer node, then set its <strong>Layout</strong> at
                    the top of the 2D editor to <strong>Full Rect</strong>. Set <strong>Ratio</strong> in the
                    AspectRatioContainer node to match your video's aspect ratio. You can use math
                    formulas in the inspector to help yourself. Remember to make one of the operands
                    a float. Otherwise, the division's result will always be an integer.</paragraph>
                <figure align="center" classes="figure-w480" ids="id1">
                    <image alt="AspectRatioContainer's Ratio property being modified in the editor inspector" candidates="{'*': 'tutorials/animation/img/playing_videos_aspect_ratio_container.png'}" original_uri="img/playing_videos_aspect_ratio_container.png" uri="tutorials/animation/img/playing_videos_aspect_ratio_container.png"></image>
                    <caption>This will evaluate to (approximately) 1.777778</caption>
                </figure>
                <paragraph>Once you've configured the AspectRatioContainer, reparent your VideoStreamPlayer
                    node to be a child of the AspectRatioContainer node. Make sure <strong>Expand</strong> is
                    enabled on the VideoStreamPlayer. Your video should now scale automatically
                    to fit the whole screen while avoiding distortion.</paragraph>
                <seealso>
                    <paragraph>See <reference internal="True" refuri="../rendering/multiple_resolutions#doc-multiple-resolutions"><inline classes="std std-ref">Multiple resolutions</inline></reference> for more tips on supporting multiple
                        aspect ratios in your project.</paragraph>
                </seealso>
            </section>
            <section ids="displaying-a-video-on-a-3d-surface" names="displaying\ a\ video\ on\ a\ 3d\ surface">
                <title>Displaying a video on a 3D surface</title>
                <paragraph>Using a VideoStreamPlayer node as a child of a <reference internal="True" refuri="../../classes/class_subviewport#class-subviewport"><inline classes="std std-ref">SubViewport</inline></reference> node,
                    it's possible to display any 2D node on a 3D surface. For example, this can be
                    used to display animated billboards when frame-by-frame animation would require
                    too much memory.</paragraph>
                <paragraph>This can be done with the following steps:</paragraph>
                <enumerated_list enumtype="arabic" prefix="" suffix=".">
                    <list_item>
                        <paragraph>Create a <reference internal="True" refuri="../../classes/class_subviewport#class-subviewport"><inline classes="std std-ref">SubViewport</inline></reference> node. Set its size to match your video's size
                            in pixels.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>Create a VideoStreamPlayer node <emphasis>as a child of the SubViewport node</emphasis> and specify
                            a video path in it. Make sure <strong>Expand</strong> is disabled, and enable <strong>Autoplay</strong> if needed.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>Create a MeshInstance3D node with a PlaneMesh or QuadMesh resource in its Mesh property.
                            Resize the mesh to match the video's aspect ratio (otherwise, it will appear distorted).</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>Create a new StandardMaterial3D resource in the <strong>Material Override</strong> property
                            in the GeometryInstance3D section.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>Enable <strong>Local To Scene</strong> in the StandardMaterial3D's Resource section (at the bottom).
                            This is <emphasis>required</emphasis> before you can use a ViewportTexture in its Albedo Texture property.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>In the StandardMaterial3D, set the <strong>Albedo &gt; Texture</strong> property to <strong>New ViewportTexture</strong>.
                            Edit the new resource by clicking it, then specify the path to the SubViewport node
                            in the <strong>Viewport Path</strong> property.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>Enable <strong>Albedo Texture Force sRGB</strong> in the StandardMaterial3D to prevent colors
                            from being washed out.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>If the billboard is supposed to emit its own light,
                            set <strong>Shading Mode</strong> to <strong>Unshaded</strong> to improve rendering performance.</paragraph>
                    </list_item>
                </enumerated_list>
                <paragraph>See <reference internal="True" refuri="../rendering/viewports#doc-viewports"><inline classes="std std-ref">Using Viewports</inline></reference> and the
                    <reference name="GUI in 3D demo" refuri="https://github.com/godotengine/godot-demo-projects/tree/master/viewport/gui_in_3d">GUI in 3D demo</reference>
                    for more information on setting this up.</paragraph>
            </section>
            <section ids="looping-a-video" names="looping\ a\ video">
                <title>Looping a video</title>
                <paragraph>For looping a video, the <strong>Loop</strong> property can be enabled. This will seamlessly
                    restart the video when it reaches its end.</paragraph>
                <paragraph>Note that setting the project setting <strong>Video Delay Compensation</strong> to a non-zero
                    value might cause your loop to not be seamless, because the synchronization of
                    audio and video takes place at the start of each loop causing occasional missed
                    frames. Set <strong>Video Delay Compensation</strong> in your project settings to <strong>0</strong> to
                    avoid frame drop issues.</paragraph>
            </section>
        </section>
        <section ids="video-decoding-conditions-and-recommended-resolutions" names="video\ decoding\ conditions\ and\ recommended\ resolutions">
            <title>Video decoding conditions and recommended resolutions</title>
            <paragraph>Video decoding is performed on the CPU, as GPUs don't have hardware acceleration
                for decoding Theora videos. Modern desktop CPUs can decode Ogg Theora videos at
                1440p @ 60 FPS or more, but low-end mobile CPUs will likely struggle with
                high-resolution videos.</paragraph>
            <paragraph>To ensure your videos decode smoothly on varied hardware:</paragraph>
            <bullet_list bullet="-">
                <list_item>
                    <paragraph>When developing games for desktop platforms, it's recommended to encode in
                        1080p at most (preferably at 30 FPS). Most people are still using 1080p or
                        lower resolution displays, so encoding higher-resolution videos may not be
                        worth the increased file size and CPU requirements.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>When developing games for mobile or web platforms, it's recommended to encode
                        in 720p at most (preferably at 30 FPS or even lower). The visual difference
                        between 720p and 1080p videos on a mobile device is usually not that
                        noticeable.</paragraph>
                </list_item>
            </bullet_list>
        </section>
        <section ids="playback-limitations" names="playback\ limitations">
            <title>Playback limitations</title>
            <paragraph>There are some limitations with the current implementation of video playback in Godot:</paragraph>
            <bullet_list bullet="-">
                <list_item>
                    <paragraph>Streaming a video from a URL is not supported.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Only mono and stereo audio output is supported. Videos with 4, 5.1 and 7.1
                        audio channels are supported but down-mixed to stereo.</paragraph>
                </list_item>
            </bullet_list>
            <target refid="doc-playing-videos-recommended-theora-encoding-settings"></target>
        </section>
        <section ids="recommended-theora-encoding-settings doc-playing-videos-recommended-theora-encoding-settings" names="recommended\ theora\ encoding\ settings doc_playing_videos_recommended_theora_encoding_settings">
            <title>Recommended Theora encoding settings</title>
            <paragraph>A word of advice is to <strong>avoid relying on built-in Ogg Theora exporters</strong> (most of the time).
                There are 2 reasons you may want to favor using an external program to encode your video:</paragraph>
            <bullet_list bullet="-">
                <list_item>
                    <paragraph>Some programs such as Blender can render to Ogg Theora. However, the default
                        quality presets are usually very low by today's standards. You may be able to
                        increase the quality options in the software you're using, but you may find
                        the output quality to remain less than ideal (given the increased file size).
                        This usually means that the software only supports encoding to constant bit
                        rate (CBR), instead of variable bit rate (VBR). VBR encoding should be
                        preferred in most scenarios as it provides a better quality to file size
                        ratio.</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Some other programs can't render to Ogg Theora at all.</paragraph>
                </list_item>
            </bullet_list>
            <paragraph>In this case, you can <strong>render the video to an intermediate high-quality format</strong>
                (such as a high-bitrate H.264 video) then re-encode it to Ogg Theora. Ideally,
                you should use a lossless or uncompressed format as an intermediate format to
                maximize the quality of the output Ogg Theora video, but this can require a lot
                of disk space.</paragraph>
            <paragraph><reference name="FFmpeg" refuri="https://ffmpeg.org/">FFmpeg</reference> (CLI) is a popular open source tool
                for this purpose. FFmpeg has a steep learning curve, but it's a powerful tool.</paragraph>
            <paragraph>Here are example FFmpeg commands to convert an MP4 video to Ogg Theora. Since
                FFmpeg supports a lot of input formats, you should be able to use the commands
                below with almost any input video format (AVI, MOV, WebM, …).</paragraph>
            <note>
                <paragraph>Make sure your copy of FFmpeg is compiled with libtheora and libvorbis support.
                    You can check this by running <literal>ffmpeg</literal> without any arguments, then looking
                    at the <literal>configuration:</literal> line in the command output.</paragraph>
            </note>
            <warning>
                <paragraph>Current official FFmpeg releases have some bugs in their Ogg/Theora
                    multiplexer. It's highly recommended to use one of the latest static daily
                    builds, or build from their master branch to get the latest fixes.</paragraph>
            </warning>
            <comment xml:space="preserve">UPDATE: When the FFmpeg bugfixes for https://trac.ffmpeg.org/ticket/11451 and</comment>
            <comment xml:space="preserve">https://trac.ffmpeg.org/ticket/11454 are included in a stable FFmpeg release,</comment>
            <comment xml:space="preserve">this warning can be removed. That will likely be FFmpeg 7.2 or 8.0, and will</comment>
            <comment xml:space="preserve">likely happen during the Godot 4.5 or 4.6 release cycle.</comment>
            <comment xml:space="preserve">Commits fixing the issues:</comment>
            <comment xml:space="preserve">- https://github.org/FFmpeg/FFmpeg@22aa71d4da37a4ad2b0d28deeace64b57aa2ef50</comment>
            <comment xml:space="preserve">- https://github.org/FFmpeg/FFmpeg@84d85e7ad4ace228265af0c8c5caccc0730042fd</comment>
            <comment xml:space="preserve">- https://github.org/FFmpeg/FFmpeg@6e26f57f672b05e7b8b052007a83aef99dc81ccb</comment>
            <section ids="balancing-quality-and-file-size" names="balancing\ quality\ and\ file\ size">
                <title>Balancing quality and file size</title>
                <paragraph>The <strong>video quality</strong> level (<literal>-q:v</literal>) must be between <literal>1</literal> and <literal>10</literal>. Quality
                    <literal>6</literal> is a good compromise between quality and file size. If encoding at a high
                    resolution (such as 1440p or 4K), you will probably want to decrease <literal>-q:v</literal> to
                    <literal>5</literal> to keep file sizes reasonable. Since pixel density is higher on a 1440p or
                    4K video, lower quality presets at higher resolutions will look as good or
                    better compared to low-resolution videos.</paragraph>
                <paragraph>The <strong>audio quality</strong> level (<literal>-q:a</literal>) must be between <literal>-1</literal> and <literal>10</literal>. Quality
                    <literal>6</literal> provides a good compromise between quality and file size. In contrast to
                    video quality, increasing audio quality doesn't increase the output file size
                    nearly as much. Therefore, if you want the cleanest audio possible, you can
                    increase this to <literal>9</literal> to get <emphasis>perceptually lossless</emphasis> audio. This is especially
                    valuable if your input file already uses lossy audio compression. Higher quality
                    audio does increase the CPU usage of the decoder, so it might lead to audio
                    dropouts in case of high system load. See
                    <reference name="this page" refuri="https://wiki.hydrogenaud.io/index.php?title=Recommended_Ogg_Vorbis#Recommended_Encoder_Settings">this page</reference>
                    for a table listing Ogg Vorbis audio quality presets and their respective
                    variable bitrates.</paragraph>
                <paragraph>The <strong>GOP (Group of Pictures) size</strong> (<literal>-g:v</literal>) is the max interval between
                    keyframes. Increasing this value can improve compression with almost no impact
                    on quality. The default size (<literal>12</literal>) is too low for most types of content,
                    it's therefore recommended using higher GOP values before reducing video
                    quality. Compression benefits will fade away as the GOP size increases though.
                    Values between <literal>64</literal> and <literal>512</literal> usually give the best compression.</paragraph>
                <note>
                    <paragraph>Higher GOP sizes will increase max seek times with a sudden increase when
                        going beyond powers of two starting at <literal>64</literal>. Max seek times with GOP size
                        <literal>65</literal> can be almost twice as long as with GOP size <literal>64</literal>, depending on
                        decoding speed.</paragraph>
                </note>
            </section>
            <section ids="ffmpeg-convert-while-preserving-original-video-resolution" names="ffmpeg:\ convert\ while\ preserving\ original\ video\ resolution">
                <title>FFmpeg: Convert while preserving original video resolution</title>
                <paragraph>The following command converts the video while keeping its original resolution.
                    The video and audio's bitrate will be variable to maximize quality while saving
                    space in parts of the video/audio that don't require a high bitrate (such as
                    static scenes).</paragraph>
                <literal_block force="False" language="gdscript" linenos="False" xml:space="preserve">ffmpeg -i input.mp4 -q:v 6 -q:a 6 -g:v 64 output.ogv</literal_block>
            </section>
            <section ids="ffmpeg-resize-the-video-then-convert-it" names="ffmpeg:\ resize\ the\ video\ then\ convert\ it">
                <title>FFmpeg: Resize the video then convert it</title>
                <paragraph>The following command resizes a video to be 720 pixels tall (720p), while
                    preserving its existing aspect ratio. This helps decrease the file size
                    significantly if the source is recorded at a higher resolution than 720p:</paragraph>
                <literal_block force="False" language="gdscript" linenos="False" xml:space="preserve">ffmpeg -i input.mp4 -vf "scale=-1:720" -q:v 6 -q:a 6 -g:v 64 output.ogv</literal_block>
                <comment xml:space="preserve">Chroma Key Functionality Documentation</comment>
            </section>
        </section>
        <section ids="chroma-key-videos" names="chroma\ key\ videos">
            <title>Chroma Key Videos</title>
            <paragraph>Chroma key, commonly known as the "green screen" or "blue screen" effect, allows you to remove a specific color from an image or video and replace it with another background. This effect is widely used in video production to composite different elements together seamlessly.</paragraph>
            <block_quote>
                <image candidates="{'*': 'tutorials/animation/img/chroma_key_video.webp'}" original_uri="img/chroma_key_video.webp" uri="tutorials/animation/img/chroma_key_video.webp"></image>
            </block_quote>
            <paragraph>We will achieve the chroma key effect by writing a custom shader in GDScript and using a <title_reference>VideoStreamPlayer</title_reference> node to display the video content.</paragraph>
            <section ids="scene-setup" names="scene\ setup">
                <title>Scene Setup</title>
                <paragraph>Ensure that the scene contains a <title_reference>VideoStreamPlayer</title_reference> node to play the video and a <title_reference>Control</title_reference> node to hold the UI elements for controlling the chroma key effect.</paragraph>
                <block_quote>
                    <image candidates="{'*': 'tutorials/animation/img/chroma_key_scene.webp'}" original_uri="img/chroma_key_scene.webp" uri="tutorials/animation/img/chroma_key_scene.webp"></image>
                </block_quote>
            </section>
            <section ids="writing-the-custom-shader" names="writing\ the\ custom\ shader">
                <title>Writing the Custom Shader</title>
                <paragraph>To implement the chroma key effect, follow these steps:</paragraph>
                <enumerated_list enumtype="arabic" prefix="" suffix=".">
                    <list_item>
                        <paragraph>Select the <title_reference>VideoStreamPlayer</title_reference> node in the scene and go to its properties. Under <title_reference>CanvasItem &gt; Material</title_reference>, create a new shader named "ChromaKeyShader.gdshader."</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>In the "ChromaKeyShader.gdshader" file, write the custom shader code as shown below:</paragraph>
                    </list_item>
                </enumerated_list>
                <literal_block force="False" highlight_args="{}" language="glsl" linenos="False" xml:space="preserve">shader_type canvas_item;

// Uniform variables for chroma key effect
uniform vec3 chroma_key_color : source_color = vec3(0.0, 1.0, 0.0);
uniform float pickup_range : hint_range(0.0, 1.0) = 0.1;
uniform float fade_amount : hint_range(0.0, 1.0) = 0.1;

void fragment() {
    // Get the color from the texture at the given UV coordinates
    vec4 color = texture(TEXTURE, UV);

    // Calculate the distance between the current color and the chroma key color
    float distance = length(color.rgb - chroma_key_color);

    // If the distance is within the pickup range, discard the pixel
    // the lesser the distance more likely the colors are
    if (distance &lt;= pickup_range) {
        discard;
    }

    // Calculate the fade factor based on the pickup range and fade amount
    float fade_factor = smoothstep(pickup_range, pickup_range + fade_amount, distance);

    // Set the output color with the original RGB values and the calculated fade factor
    COLOR = vec4(color.rgb, fade_factor);
}</literal_block>
                <paragraph>The shader uses the distance calculation to identify pixels close to the chroma key color and discards them,
                    effectively removing the selected color. Pixels that are slightly further away from the chroma key color are
                    faded based on the fade_factor, blending them smoothly with the surrounding colors.
                    This process creates the desired chroma key effect, making it appear as if the background has been replaced with
                    another image or video.</paragraph>
                <paragraph>The code above represents a simple demonstration of the Chroma Key shader,
                    and users can customize it according to their specific requirements.</paragraph>
            </section>
            <section ids="ui-controls" names="ui\ controls">
                <title>UI Controls</title>
                <paragraph>To allow users to manipulate the chroma key effect in real-time, we created sliders in the <title_reference>Control</title_reference> node. The <title_reference>Control</title_reference> node's script contains the following functions:</paragraph>
                <container classes="sphinx-tabs" type="tab-element">
                    <div aria-label="Tabbed content" role="tablist">
                        <button aria-controls="panel-0-R0RTY3JpcHQ=" aria-selected="true" classes="sphinx-tabs-tab code-tab group-tab" ids="tab-0-R0RTY3JpcHQ=" name="R0RTY3JpcHQ=" role="tab" tabindex="0">GDScript</button>
                        <button aria-controls="panel-0-QyM=" aria-selected="false" classes="sphinx-tabs-tab code-tab group-tab" ids="tab-0-QyM=" name="QyM=" role="tab" tabindex="-1">C#</button>
                    </div>
                    <div aria-labelledby="tab-0-R0RTY3JpcHQ=" classes="sphinx-tabs-panel code-tab group-tab" ids="panel-0-R0RTY3JpcHQ=" name="R0RTY3JpcHQ=" role="tabpanel" tabindex="0">
                        <literal_block force="False" highlight_args="{}" language="gdscript" linenos="False" xml:space="preserve"> extends Control

 func _on_color_picker_button_color_changed(color):
     # Update the "chroma_key_color" shader parameter of the VideoStreamPlayer's material.
     $VideoStreamPlayer.material.set("shader_parameter/chroma_key_color", color)

 func _on_h_slider_value_changed(value):
     # Update the "pickup_range" shader parameter of the VideoStreamPlayer's material.
     $VideoStreamPlayer.material.set("shader_parameter/pickup_range", value)

 func _on_h_slider_2_value_changed(value):
     # Update the "fade_amount" shader parameter of the VideoStreamPlayer's material.
     $VideoStreamPlayer.material.set("shader_parameter/fade_amount", value)

func _on_video_stream_player_finished():
     # Restart the video playback when it's finished.
     $VideoStreamPlayer.play()</literal_block>
                    </div>
                    <div aria-labelledby="tab-0-QyM=" classes="sphinx-tabs-panel code-tab group-tab" hidden="true" ids="panel-0-QyM=" name="QyM=" role="tabpanel" tabindex="0">
                        <literal_block force="False" highlight_args="{}" language="csharp" linenos="False" xml:space="preserve">using Godot;

public partial class MyControl : Control
{
    private VideoStreamPlayer _videoStreamPlayer;

    public override void _Ready()
    {
        _videoStreamPlayer = GetNode&lt;VideoStreamPlayer&gt;("VideoStreamPlayer");
    }

    private void OnColorPickerButtonColorChanged(Color color)
    {
        // Update the "chroma_key_color" shader parameter of the VideoStreamPlayer's material.
        _videoStreamPlayer.Material.Set("shader_parameter/chroma_key_color", color);
    }

    private void OnHSliderValueChanged(double value)
    {
        // Update the "pickup_range" shader parameter of the VideoStreamPlayer's material.
        _videoStreamPlayer.Material.Set("shader_parameter/pickup_range", value);
    }

    private void OnHSlider2ValueChanged(double value)
    {
        // Update the "fade_amount" shader parameter of the VideoStreamPlayer's material.
        _videoStreamPlayer.Material.Set("shader_parameter/fade_amount", value);
    }

    private void OnVideoStreamPlayerFinished()
    {
        // Restart the video playback when it's finished.
        _videoStreamPlayer.Play();
    }
}</literal_block>
                    </div>
                </container>
                <paragraph>also make sure that the range of the sliders are appropriate, our settings are :</paragraph>
                <block_quote>
                    <image candidates="{'*': 'tutorials/animation/img/slider_range.webp'}" original_uri="img/slider_range.webp" uri="tutorials/animation/img/slider_range.webp"></image>
                </block_quote>
            </section>
            <section ids="signal-handling" names="signal\ handling">
                <title>Signal Handling</title>
                <paragraph>Connect the appropriate signal from the UI elements to the <title_reference>Control</title_reference> node's script.
                    you created in the <title_reference>Control</title_reference> node's script to control the chroma key effect.
                    These signal handlers will update the shader's uniform variables
                    in response to user input.</paragraph>
                <paragraph>Save and run the scene to see the chroma key effect in action! With the provided UI controls,
                    you can now adjust the chroma key color, pickup range, and fade amount in real-time, achieving the desired
                    chroma key functionality for your video content.</paragraph>
                <substitution_definition names="weblate_widget"><reference refuri="https://hosted.weblate.org/engage/godot-engine/?utm_source=widget"><image alt="Translation status" candidates="{'?': 'https://hosted.weblate.org/widgets/godot-engine/-/godot-docs/287x66-white.png'}" height="66" uri="https://hosted.weblate.org/widgets/godot-engine/-/godot-docs/287x66-white.png" width="287"></image></reference></substitution_definition>
            </section>
        </section>
    </section>
</document>
